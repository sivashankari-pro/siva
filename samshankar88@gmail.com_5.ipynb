{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        y     proba\n",
      "5012  1.0  0.500019\n",
      "805   1.0  0.500047\n",
      "7421  1.0  0.500058\n",
      "1630  1.0  0.500058\n",
      "8294  1.0  0.500081\n",
      "5097  1.0  0.500198\n",
      "2783  1.0  0.500200\n",
      "4403  1.0  0.500244\n",
      "1849  1.0  0.500301\n",
      "1979  1.0  0.500308\n",
      "********************-------------------CONFUSION MATRIX-----------------*********************\n",
      "Y_ACTUAL  0.0    1.0\n",
      "Y_PRED              \n",
      "1         100  10000\n",
      "  ******************F1-SCORE*************\n",
      "0.9950248756218906\n",
      " \n",
      "****************** ACCURACY SCORE*****************\n",
      "0.9900990099009901\n",
      "************AUC SCORE*********\n",
      " \n",
      "0.488299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4141: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  infer_datetime_format=infer_datetime_format)\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "a1=pd.read_csv(\"5_a.csv\")\n",
    "\n",
    "a5=a1.sort_values(by=[\"proba\"])\n",
    "print(a5.head(10))\n",
    "col_name=['Y_ACTUAL','Y_SCORE']\n",
    "\n",
    "a5.columns=col_name\n",
    "y_actu = pd.Series.from_csv('5_a.csv')\n",
    "\n",
    "for i in a5:  \n",
    "    a5[\"Y_PRED\"] = np.where(a5[\"Y_SCORE\"]<0.5, '0', '1')\n",
    "\n",
    "\n",
    "\n",
    "arr=a5[\"Y_ACTUAL\"].to_numpy()\n",
    "ar=a5[\"Y_PRED\"].to_numpy()\n",
    "score=a5[\"Y_SCORE\"].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_confusion = pd.crosstab(a5[\"Y_PRED\"],a5[\"Y_ACTUAL\"])\n",
    "col_n=['Y_ACTUAL','Y_PRED']\n",
    "print(\"********************-------------------CONFUSION MATRIX-----------------*********************\")\n",
    "print(df_confusion)\n",
    "num=df_confusion.iloc[0,1]\n",
    "\n",
    "pre_d=df_confusion.sum(axis=1)\n",
    "pre=(num/pre_d)\n",
    "re_d=df_confusion.sum(axis=0)\n",
    "re=(num/re_d[1])\n",
    "a=pre*re\n",
    "b=pre+re\n",
    "c=a/b\n",
    "f1=2*c\n",
    "f11=f1[0]\n",
    "t=(re_d[0]+re_d[1])\n",
    "\n",
    "acc=(num)/t\n",
    "print(\" \" , \"******************F1-SCORE*************\")\n",
    "print(f11)\n",
    "print(\" \")\n",
    "print(\"****************** ACCURACY SCORE*****************\")\n",
    "print(acc)\n",
    "def fast_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc\n",
    "auc_r=fast_auc(arr,score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"************AUC SCORE*********\")\n",
    "print(\" \")\n",
    "print(auc_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "\n",
    "\n",
    "<pre>\n",
    "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Y_ACTUAL1  Y_SCORE1 Y_PRED1\n",
      "8446        1.0  0.595294       1\n",
      "1978        1.0  0.594808       1\n",
      "1657        1.0  0.592198       1\n",
      "110         1.0  0.590171       1\n",
      "8578        1.0  0.588718       1\n",
      "2208        1.0  0.585175       1\n",
      "7811        1.0  0.583235       1\n",
      "7042        1.0  0.582210       1\n",
      "2183        1.0  0.582020       1\n",
      "7863        1.0  0.581772       1\n",
      "Y_PRED1       0    1\n",
      "Y_ACTUAL1           \n",
      "0.0        9761  239\n",
      "1.0          45   55\n",
      "  ******************F1-SCORE*************\n",
      "0.2791878172588833\n",
      " \n",
      "****************** ACCURACY SCORE*****************\n",
      "0.9718811881188119\n",
      "********auc******\n",
      "0.937757\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "b1=pd.read_csv(\"5_b.csv\")\n",
    "b5=b1.sort_values(by=[\"proba\"],ascending=False)\n",
    "\n",
    "col_name=['Y_ACTUAL1','Y_SCORE1']\n",
    "b5.columns=col_name\n",
    "\n",
    "\n",
    "\n",
    "for i in b5:  \n",
    "    b5[\"Y_PRED1\"] = np.where(b5[\"Y_SCORE1\"]<0.5, '0', '1')\n",
    "\n",
    "print(b5.head(10))    \n",
    "    \n",
    "arr=b5[\"Y_ACTUAL1\"].to_numpy()\n",
    "\n",
    "ar=b5[\"Y_PRED1\"].to_numpy()\n",
    "score=b5[\"Y_SCORE1\"].to_numpy()\n",
    "\n",
    "df_confusion = pd.crosstab(b5[\"Y_ACTUAL1\"],b5[\"Y_PRED1\"])\n",
    "col_n=['Y_ACTUAL','Y_PRED']\n",
    "print(df_confusion)\n",
    "pre_d=df_confusion.iloc[0,0]+df_confusion.iloc[1,1]\n",
    "\n",
    "re_dd=df_confusion.sum(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "pre_dd=df_confusion.sum(axis=1)\n",
    "\n",
    "t=re_dd[0]+re_dd[1]\n",
    "\n",
    "\n",
    "\n",
    "num=df_confusion.iloc[1,1]\n",
    "\n",
    "pre=num/pre_dd[1]\n",
    "re=num/re_dd[1]\n",
    "\n",
    "a1=pre*re\n",
    "b1=pre+re\n",
    "c1=a1/b1\n",
    "f11=2*c1\n",
    "\n",
    "acc=pre_d/t\n",
    "print(\" \" , \"******************F1-SCORE*************\")\n",
    "print(f11)\n",
    "print(\" \")\n",
    "print(\"****************** ACCURACY SCORE*****************\")\n",
    "print(acc)\n",
    "P = sum(arr)\n",
    "\n",
    "N = len(arr) - P\n",
    "def fast_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc\n",
    "auc_r=fast_auc(arr,score)\n",
    "print(\"********auc******\")\n",
    "print(auc_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false positives} + 100 \\times \\text{numebr of false negatives}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points < number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre> \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ACTUAL1           1\n",
      "Y_SCORE1     0.236307\n",
      "Y_PRED1             0\n",
      "A              104600\n",
      "Name: 2436, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# write your code\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "  \n",
    "c1=pd.read_csv(\"5_c.csv\")\n",
    "c5=c1.sort_values(by=[\"prob\"],ascending=False)\n",
    "\n",
    "col_name=['Y_ACTUAL1','Y_SCORE1']\n",
    "\n",
    "c5.columns=col_name\n",
    "arr=c5[\"Y_ACTUAL1\"].to_numpy()\n",
    "\n",
    "\n",
    "for ind in c5.index: \n",
    "    \n",
    "         c5[\"Y_PRED1\"] = np.where(c5[\"Y_SCORE1\"] < c5['Y_SCORE1'][ind], '0', '1')\n",
    "         df_confusion = pd.crosstab(c5[\"Y_PRED1\"],c5[\"Y_ACTUAL1\"]) \n",
    "         FN=df_confusion.iloc[0,1]\n",
    "         FP=(df_confusion.iloc[1,0])\n",
    "         A=500*FP+100*FN\n",
    "         c5[\"A\"]=A\n",
    "         c55=c5.sort_values(by=[\"A\"],ascending=True)\n",
    "         c55[['A']].idxmin()\n",
    "         print(c55.loc[2436])\n",
    "         break\n",
    "         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       y   pred\n",
      "0  101.0  100.0\n",
      "1  120.0  100.0\n",
      "2  131.0  113.0\n",
      "3  164.0  125.0\n",
      "4  154.0  152.0\n",
      "5  133.0  153.0\n",
      "6  148.0  139.0\n",
      "7  172.0  145.0\n",
      "8  153.0  162.0\n",
      "9  162.0  154.0\n",
      "*************************MSE***************************\n",
      "177.16569974554707\n",
      "*************************R2********************************\n",
      "{'polynomial': [-0.00022020806586424958, 1.0022570355830112, 1.6409752402852686], 'determination': 0.9567474050357758}\n",
      "************************MAPE1******************************\n",
      "0.12927250737711504\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "d5=pd.read_csv(\"5_d.csv\")\n",
    "print(d5.head(10))\n",
    "MSE = np.square(np.subtract(d5[\"y\"],d5[\"pred\"])).mean() \n",
    "\n",
    "def mape_vectorized_v2(a, b,c): \n",
    "    a,b=np.array(a),np.array(b)\n",
    "    return np.mean(np.abs((a - b)/c))\n",
    "\n",
    "\n",
    "\n",
    "def polyfit(x, y, degree):\n",
    "    results = {}\n",
    "\n",
    "    coeffs = np.polyfit(x, y, degree)\n",
    "\n",
    "    \n",
    "    results['polynomial'] = coeffs.tolist()\n",
    "\n",
    "  \n",
    "    p = np.poly1d(coeffs)\n",
    "   \n",
    "    yhat = p(x)                       \n",
    "    ybar = np.sum(y)/len(y)         \n",
    "    sstot = np.sum((y - ybar)**2) \n",
    "    ssres=  np.sum((y-yhat)**2)\n",
    "    results['determination'] =(1-(ssres / sstot))\n",
    "    return results\n",
    "\n",
    "aa=d5[\"pred\"].mean()\n",
    "MAPE1=mape_vectorized_v2(d5[\"y\"],d5[\"pred\"],aa)\n",
    "R2=polyfit(d5[\"y\"],d5[\"pred\"],2)\n",
    "print(\"*************************MSE***************************\")\n",
    "print(MSE)\n",
    "print(\"*************************R2********************************\")\n",
    "print(R2)\n",
    "print(\"************************MAPE1******************************\")      \n",
    "print(MAPE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
